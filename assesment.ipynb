{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alejandro SÃ¡nchez MonzÃ³n - Assesment Clarity AI (04/06/2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Please read the README.md file to understand more about my intentions and thoughts during the assesment development. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncomment this line and install pandas in case you don't have it i your local environment.\n",
    "## pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line won't work if you didn't install pandas using the above command.\n",
    "# https://pandas.pydata.org/docs/\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fisrt of all, I found usefull to check if the timestamp received is valid or not.\n",
    "def is_timestamp_valid(timestamp):\n",
    "    try:\n",
    "        pd.to_datetime(timestamp, unit='ms')\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can check too if the file received is valid or not.\n",
    "def is_file_valid(file_name):\n",
    "    try:\n",
    "        pd.read_csv(file_name, sep=' ', names=['unix_timestamp', 'hostname_1', 'hostname_2'])\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create the function with the logic required.\n",
    "\n",
    "def parsing_tool(file_name, init_datetime, end_datetime, hostname):\n",
    "    # I will check first if the timestamp received is valid or not.\n",
    "    if not is_timestamp_valid(init_datetime) or not is_timestamp_valid(end_datetime):\n",
    "        raise ValueError('The timestamp received is not valid.')\n",
    "\n",
    "    # I will check if the file received is valid or not.\n",
    "    if not is_file_valid(file_name):\n",
    "        raise Exception('The file received is not valid.')\n",
    "\n",
    "    # I need to parse to datetime object the init_datetime and end_datetime variables.\n",
    "    init_datetime = pd.to_datetime(init_datetime, unit='ms')\n",
    "    end_datetime = pd.to_datetime(end_datetime, unit='ms')\n",
    "\n",
    "    # I will read all the lines of the file, naming the columns as the format given.\n",
    "    df = pd.read_csv(file_name, sep=' ', names=['unix_timestamp', 'hostname_1', 'hostname_2'])\n",
    "\n",
    "    time_parsed = pd.to_datetime(df['unix_timestamp'], unit='ms')\n",
    "\n",
    "    # I am going to filter the dataframe based on the init_datetime and end_datetime variables.\n",
    "    df_filtered = df[(time_parsed >= init_datetime) & (time_parsed <= end_datetime)]\n",
    "\n",
    "    # Now, I continue filtering the dataframe based on the hostname variable.\n",
    "    df_filtered = df_filtered[(df_filtered['hostname_2'] == hostname)]\n",
    "\n",
    "    # We apply the unique() and tolist() functions to get a list with the unique hostnames (no duplicates).\n",
    "    return df_filtered['hostname_1'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At the end, we call the function with all the required parameters.\n",
    "\n",
    "hostname = 'Taffani'\n",
    "file_name = 'input-file-10000.txt'\n",
    "init_datetime = '1565647518147'\n",
    "end_datetime = '1565649996495'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3563/1821696467.py:4: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  pd.to_datetime(timestamp, unit='ms')\n",
      "/tmp/ipykernel_3563/3208315586.py:13: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  init_datetime = pd.to_datetime(init_datetime, unit='ms')\n",
      "/tmp/ipykernel_3563/3208315586.py:14: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  end_datetime = pd.to_datetime(end_datetime, unit='ms')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Chessica', 'Shaunee', 'Mehret']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = parsing_tool(file_name, init_datetime, end_datetime, hostname)\n",
    "\n",
    "df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative: using user inputs by console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3563/1821696467.py:4: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  pd.to_datetime(timestamp, unit='ms')\n",
      "/tmp/ipykernel_3563/3208315586.py:13: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  init_datetime = pd.to_datetime(init_datetime, unit='ms')\n",
      "/tmp/ipykernel_3563/3208315586.py:14: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  end_datetime = pd.to_datetime(end_datetime, unit='ms')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Kaitley',\n",
       " 'Rashawna',\n",
       " 'Zebastian',\n",
       " 'Lacinda',\n",
       " 'Jaylen',\n",
       " 'Hashem',\n",
       " 'Chasten',\n",
       " 'Karletta',\n",
       " 'Rukaya',\n",
       " 'Giany',\n",
       " 'Jitesh',\n",
       " 'Arisleidy',\n",
       " 'Edrin']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hostname_input = input(\"Enter the hostname: \") #Alizander\n",
    "end_datetime_input = input(\"Enter the end datetime (ms): \") #1565727297921\n",
    "init_datetime_input = input(\"Enter the init datetime (ms): \") #1565656183599\n",
    "file_name_input = input(\"Enter the file name: \") #input-file-10000.txt\n",
    "\n",
    "df_result_inputs = parsing_tool(file_name_input, init_datetime_input, end_datetime_input, hostname_input)\n",
    "\n",
    "df_result_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing for these functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As I said in the README.md, I am using Anaconda and I am not sure if it preinstall the unittest librery so y add the install command below.\n",
    "# pip install unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I import the testing library I am going to use to test my functions.\n",
    "\n",
    "import unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3563/1821696467.py:4: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  pd.to_datetime(timestamp, unit='ms')\n",
      "/tmp/ipykernel_3563/3208315586.py:13: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  init_datetime = pd.to_datetime(init_datetime, unit='ms')\n",
      "/tmp/ipykernel_3563/3208315586.py:14: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  end_datetime = pd.to_datetime(end_datetime, unit='ms')\n",
      "./tmp/ipykernel_3563/1821696467.py:4: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  pd.to_datetime(timestamp, unit='ms')\n",
      "./tmp/ipykernel_3563/3208315586.py:13: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  init_datetime = pd.to_datetime(init_datetime, unit='ms')\n",
      "/tmp/ipykernel_3563/3208315586.py:14: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  end_datetime = pd.to_datetime(end_datetime, unit='ms')\n",
      "../tmp/ipykernel_3563/1821696467.py:4: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  pd.to_datetime(timestamp, unit='ms')\n",
      "/tmp/ipykernel_3563/3208315586.py:13: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  init_datetime = pd.to_datetime(init_datetime, unit='ms')\n",
      "/tmp/ipykernel_3563/3208315586.py:14: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  end_datetime = pd.to_datetime(end_datetime, unit='ms')\n",
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.098s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7f90fe0f8510>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I create a class with my functions to test the original ones.\n",
    "\n",
    "class TestParsingTool(unittest.TestCase):\n",
    "    def test_is_timestamp_valid_raise_valueerror(self):\n",
    "        test_file_name = 'input-file-10000.txt'\n",
    "        test_end_datetime = '1565649996495'\n",
    "        test_init_datetime = 'INVALID_TIMESTAMP'\n",
    "        test_hostname = 'Taffani'\n",
    "\n",
    "        with self.assertRaises(ValueError):\n",
    "            parsing_tool(test_file_name, test_init_datetime, test_end_datetime, test_hostname)\n",
    "\n",
    "    def test_is_timestamp_valid(self):\n",
    "        test_file_name = 'input-file-10000.txt'\n",
    "        test_end_datetime = '1565649996495'\n",
    "        test_init_datetime = '1565647518147'\n",
    "        test_hostname = 'Taffani'\n",
    "\n",
    "        test_result = parsing_tool(test_file_name, test_init_datetime, test_end_datetime, test_hostname)\n",
    "        self.assertIn('Shaunee', test_result)\n",
    "\n",
    "    def test_is_file_valid_raise_exception(self):\n",
    "        test_file_name = 'INVALID_FILE.txt'\n",
    "        test_end_datetime = '1565649996495'\n",
    "        test_init_datetime = '1565647518147'\n",
    "        test_hostname = 'Taffani'\n",
    "\n",
    "        with self.assertRaises(Exception):\n",
    "            parsing_tool(test_file_name, test_init_datetime, test_end_datetime, test_hostname)\n",
    "\n",
    "    def test_is_file_valid(self):\n",
    "        test_file_name = 'input-file-10000.txt'\n",
    "        test_end_datetime = '1565649996495'\n",
    "        test_init_datetime = '1565647518147'\n",
    "        test_hostname = 'Taffani'\n",
    "\n",
    "        test_result = parsing_tool(test_file_name, test_init_datetime, test_end_datetime, test_hostname)\n",
    "        self.assertIn('Shaunee', test_result)\n",
    "\n",
    "    def test_parsing_tool(self):\n",
    "        test_file_name = 'input-file-10000.txt'\n",
    "        test_end_datetime = '1565649996495'\n",
    "        test_init_datetime = '1565647518147'\n",
    "        test_hostname = 'Taffani'\n",
    "\n",
    "        test_result = parsing_tool(test_file_name, test_init_datetime, test_end_datetime, test_hostname)\n",
    "        self.assertIn('Shaunee', test_result)\n",
    "\n",
    "\n",
    "unittest.main(argv=[''], exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional requirement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this challenge, in a simpler way, I have decided to use a **while True** to execute the functions continuously. But in a working environment, I would voluntarily like to comment on the idea that you could use some kind of **Cron** or **Job Scheduling** to call the functions only when necessary, and thus have a much more efficient performance.\n",
    "- https://advsyscon.com/blog/python-job-scheduling/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will need some more libraries this time in order to use threading correctly and work with timestamps.\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_realtime = 'input-file-10000.txt'\n",
    "df_realtime = pd.DataFrame(columns=['unix_timestamp', 'hostname_1', 'hostname_2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the **update_data()** function, I assume that the file to be analyzed will always have the same name, so I do not perform validations on it, and I also assume that, since the file is the same, I use the skiprows attribute of **read_csv()** and **concat** to constantly update the new information with the information that already exists today without re-reading the whole new file from top to bottom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will be called in a thread and continuously update the dataframe.\n",
    "def update_data():\n",
    "    global df_realtime\n",
    "\n",
    "    while True:\n",
    "        # I read the file and create a new dataframe with only the new information.\n",
    "        new_df = pd.read_csv(file_name_realtime, sep=' ', names=['unix_timestamp', 'hostname_1', 'hostname_2'], skiprows=len(df_realtime))\n",
    "        new_df['unix_timestamp'] = pd.to_datetime(new_df['unix_timestamp'], unit='ms')\n",
    "\n",
    "        # I update the dataframe with the new information.\n",
    "        df_realtime = pd.concat([df_realtime, new_df])\n",
    "\n",
    "        time.sleep(60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will be called in a thread and will generate the report where I collect data such as hostnames connected, received and most connected.\n",
    "def generate_report(last_timestamp, df_realtime, hostname):\n",
    "    while True:\n",
    "        actual_time = datetime.now()\n",
    "\n",
    "        # I check here if he hour is passed or not.\n",
    "        if actual_time - last_timestamp >= timedelta(hours=1):\n",
    "            last_timestamp = actual_time\n",
    "            hour_aux = actual_time - timedelta(hours=1)\n",
    "\n",
    "            # I create a Dataframe with the information of the last hour.\n",
    "            last_hour_df = df_realtime[(df_realtime['unix_timestamp'] >= hour_aux) & (df_realtime['unix_timestamp'] <= actual_time)]\n",
    "\n",
    "            hostnames_connected = last_hour_df[last_hour_df['hostname_1'] == hostname]['hostname_2'].unique().tolist()\n",
    "            hostnames_received = last_hour_df[last_hour_df['hostname_2'] == hostname]['hostname_1'].unique().tolist()\n",
    "\n",
    "            # idxmax() returns the index of the maximum value, but I need to ensure there are values.\n",
    "            most_connections = last_hour_df['hostname_1'].value_counts().idxmax() if not last_hour_df.empty else None\n",
    "\n",
    "            print(f'Hostnames connected in the last hour: {hostnames_connected}')\n",
    "            print(f'Hostnames received in the last hour: {hostnames_received}')\n",
    "            print(f'Most connected in the last hour: {most_connections}')\n",
    "            print('-------------------------------------------')\n",
    "\n",
    "            # I decided to save the report in a csv file as well as I print the information.\n",
    "            csv_title_time = int(actual_time.timestamp() * 1000)\n",
    "            pd.DataFrame({'hostnames_connected': hostnames_connected, 'hostnames_received': hostnames_received, 'most_connected': most_connections}).to_csv(f'output/report_{csv_title_time}.csv', index=False)\n",
    "\n",
    "        time.sleep(60 * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, I am ready to call the threads and generate the reports.\n",
    "monitor_thread = threading.Thread(target=update_data)\n",
    "\n",
    "# I start the threads.\n",
    "monitor_thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hostnames connected in the last hour: []\n",
      "Hostnames received in the last hour: []\n",
      "Most connected in the last hour: None\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m last_timestamp_realtime \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow() \u001b[38;5;241m-\u001b[39m timedelta(hours\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      2\u001b[0m hostname_realtime \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTaffani\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 4\u001b[0m generate_report(last_timestamp_realtime, df_realtime, hostname_realtime)\n",
      "Cell \u001b[0;32mIn[23], line 29\u001b[0m, in \u001b[0;36mgenerate_report\u001b[0;34m(last_timestamp, df_realtime, hostname)\u001b[0m\n\u001b[1;32m     26\u001b[0m     csv_title_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(actual_time\u001b[38;5;241m.\u001b[39mtimestamp() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m)\n\u001b[1;32m     27\u001b[0m     pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhostnames_connected\u001b[39m\u001b[38;5;124m'\u001b[39m: hostnames_connected, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhostnames_received\u001b[39m\u001b[38;5;124m'\u001b[39m: hostnames_received, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmost_connected\u001b[39m\u001b[38;5;124m'\u001b[39m: most_connections})\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput/report_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcsv_title_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 29\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m60\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m60\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataframe: 10000\n"
     ]
    }
   ],
   "source": [
    "last_timestamp_realtime = datetime.now() - timedelta(hours=1)\n",
    "hostname_realtime = 'Taffani'\n",
    "\n",
    "generate_report(last_timestamp_realtime, df_realtime, hostname_realtime)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
